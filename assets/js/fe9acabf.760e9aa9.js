"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[330],{3952:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>s,default:()=>p,frontMatter:()=>o,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"module-03-isaac-brain/week-08-isaac","title":"Week 8: NVIDIA Isaac","description":"Mastering the Foundation of Robotic Intelligence","source":"@site/docs/module-03-isaac-brain/week-08-isaac.md","sourceDirName":"module-03-isaac-brain","slug":"/module-03-isaac-brain/week-08-isaac","permalink":"/docs/module-03-isaac-brain/week-08-isaac","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-03-isaac-brain/week-08-isaac.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Week 8: NVIDIA Isaac","sidebar_position":1},"sidebar":"modulesSidebar","previous":{"title":"Week 7: URDF & SDF","permalink":"/docs/module-02-digital-twin/week-07-urdf"},"next":{"title":"Week 9: Perception","permalink":"/docs/module-03-isaac-brain/week-09-perception"}}');var r=i(4848),a=i(8453);const o={title:"Week 8: NVIDIA Isaac",sidebar_position:1},s="Week 8: NVIDIA Isaac SDK and Isaac Sim - The AI Robotics Platform",c={},l=[{value:"Mastering the Foundation of Robotic Intelligence",id:"mastering-the-foundation-of-robotic-intelligence",level:2},{value:"NVIDIA Isaac Ecosystem Overview",id:"nvidia-isaac-ecosystem-overview",level:2},{value:"The Complete AI Robotics Stack",id:"the-complete-ai-robotics-stack",level:3},{value:"Why Isaac Matters",id:"why-isaac-matters",level:3},{value:"Isaac SDK: The Development Framework",id:"isaac-sdk-the-development-framework",level:2},{value:"Core Architecture",id:"core-architecture",level:3},{value:"Key Components",id:"key-components",level:3},{value:"Graph-Based Programming",id:"graph-based-programming",level:3},{value:"Isaac Sim: The AI Training Environment",id:"isaac-sim-the-ai-training-environment",level:2},{value:"Photorealistic Simulation",id:"photorealistic-simulation",level:3},{value:"Synthetic Data Generation",id:"synthetic-data-generation",level:3},{value:"Domain Randomization",id:"domain-randomization",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"TensorRT Integration",id:"tensorrt-integration",level:3},{value:"Multi-GPU and Multi-Node Training",id:"multi-gpu-and-multi-node-training",level:3},{value:"Integration with ROS 2",id:"integration-with-ros-2",level:2},{value:"Isaac ROS Bridge",id:"isaac-ros-bridge",level:3},{value:"Debugging and Profiling",id:"debugging-and-profiling",level:2},{value:"Performance Monitoring",id:"performance-monitoring",level:3},{value:"Memory Optimization",id:"memory-optimization",level:3},{value:"\ud83c\udfaf Weekly Project: Isaac Perception Pipeline",id:"-weekly-project-isaac-perception-pipeline",level:2},{value:"Key Takeaways",id:"key-takeaways",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"week-8-nvidia-isaac-sdk-and-isaac-sim---the-ai-robotics-platform",children:"Week 8: NVIDIA Isaac SDK and Isaac Sim - The AI Robotics Platform"})}),"\n",(0,r.jsx)(n.h2,{id:"mastering-the-foundation-of-robotic-intelligence",children:"Mastering the Foundation of Robotic Intelligence"}),"\n",(0,r.jsxs)(n.p,{children:["Welcome to the world of ",(0,r.jsx)(n.strong,{children:"NVIDIA Isaac"}),", the comprehensive platform that brings AI to robotics. This week introduces you to the Isaac SDK and Isaac Sim, providing the tools and environments needed to create intelligent robotic systems. You'll learn to harness GPU acceleration for real-time AI inference, synthetic data generation, and simulation-based training that bridges the gap between virtual development and physical deployment."]}),"\n",(0,r.jsx)(n.h2,{id:"nvidia-isaac-ecosystem-overview",children:"NVIDIA Isaac Ecosystem Overview"}),"\n",(0,r.jsx)(n.h3,{id:"the-complete-ai-robotics-stack",children:"The Complete AI Robotics Stack"}),"\n",(0,r.jsx)(n.p,{children:"Isaac represents NVIDIA's end-to-end solution for robotic AI:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Isaac SDK"}),": Core framework for building and deploying AI applications"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Isaac Sim"}),": Photorealistic simulation environment for AI training"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Isaac ROS"}),": ROS 2 integration for seamless robotic development"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Isaac Replicator"}),": Synthetic data generation and domain randomization"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Isaac Perceptor"}),": Pre-built perception pipelines"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"why-isaac-matters",children:"Why Isaac Matters"}),"\n",(0,r.jsx)(n.p,{children:"Traditional robotics development faces significant challenges:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Data Scarcity"}),": Limited labeled datasets for training"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sim-to-Real Gap"}),": Models trained in simulation fail in reality"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Real-Time Constraints"}),": AI inference must happen fast enough for control"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Edge Deployment"}),": Limited computational resources on robots"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Isaac addresses these challenges through:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Synthetic Data"}),": Generate unlimited training data"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Domain Randomization"}),": Robust models that work in varied conditions"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"GPU Acceleration"}),": Real-time inference on edge devices"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Unified Pipeline"}),": From simulation to deployment"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"isaac-sdk-the-development-framework",children:"Isaac SDK: The Development Framework"}),"\n",(0,r.jsx)(n.h3,{id:"core-architecture",children:"Core Architecture"}),"\n",(0,r.jsx)(n.p,{children:'Isaac SDK uses a component-based architecture called "Gems":'}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Basic Isaac application structure\nfrom isaac import Application\n\napp = Application()\n\n# Add processing components (Gems)\ncamera = app.add("Camera")\nimage_processor = app.add("ImageProcessor") \nobject_detector = app.add("ObjectDetector")\npose_estimator = app.add("PoseEstimator")\n\n# Connect components in a processing graph\napp.connect(camera, "image", image_processor, "input")\napp.connect(image_processor, "processed", object_detector, "input")\napp.connect(object_detector, "detections", pose_estimator, "detections")\n\n# Configure parameters\napp.set_parameter("Camera", "resolution", [1920, 1080])\napp.set_parameter("ObjectDetector", "model_path", "/path/to/model.onnx")\n\n# Run the application\napp.run()\n'})}),"\n",(0,r.jsx)(n.h3,{id:"key-components",children:"Key Components"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Perception Gems"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Computer vision pipeline\nclass PerceptionPipeline:\n    def __init__(self):\n        self.camera = IsaacCamera()\n        self.preprocessor = ImagePreprocessor()\n        self.detector = ObjectDetector(model="yolov5")\n        self.tracker = ObjectTracker()\n        \n    def process_frame(self, frame):\n        # Preprocess image\n        processed = self.preprocessor.normalize(frame)\n        \n        # Detect objects\n        detections = self.detector.detect(processed)\n        \n        # Track across frames\n        tracks = self.tracker.update(detections)\n        \n        return tracks\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Control Gems"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Robotic control pipeline\nclass ControlPipeline:\n    def __init__(self):\n        self.planner = MotionPlanner()\n        self.controller = JointController()\n        self.safety_monitor = SafetyMonitor()\n        \n    def execute_motion(self, target_pose):\n        # Plan trajectory\n        trajectory = self.planner.plan_trajectory(\n            current_pose=self.get_current_pose(),\n            target_pose=target_pose\n        )\n        \n        # Check safety\n        if not self.safety_monitor.validate_trajectory(trajectory):\n            return False\n            \n        # Execute motion\n        success = self.controller.execute_trajectory(trajectory)\n        return success\n"})}),"\n",(0,r.jsx)(n.h3,{id:"graph-based-programming",children:"Graph-Based Programming"}),"\n",(0,r.jsx)(n.p,{children:"Isaac's visual programming interface allows drag-and-drop development:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Graph definition (JSON-like structure)\ngraph_config = {\n    "nodes": [\n        {\n            "name": "camera",\n            "component": "IsaacCamera",\n            "parameters": {"device": 0}\n        },\n        {\n            "name": "detector", \n            "component": "ObjectDetector",\n            "parameters": {"model": "yolov5.onnx"}\n        }\n    ],\n    "edges": [\n        {\n            "source": "camera.image",\n            "target": "detector.input"\n        }\n    ]\n}\n\n# Load and run graph\napp = Application()\napp.load_graph(graph_config)\napp.run()\n'})}),"\n",(0,r.jsx)(n.h2,{id:"isaac-sim-the-ai-training-environment",children:"Isaac Sim: The AI Training Environment"}),"\n",(0,r.jsx)(n.h3,{id:"photorealistic-simulation",children:"Photorealistic Simulation"}),"\n",(0,r.jsx)(n.p,{children:"Isaac Sim provides physically accurate rendering for AI training:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import isaacsim\n\n# Initialize simulation\nsim = isaacsim.Simulation()\n\n# Load environment\nwarehouse = sim.load_environment("warehouse.usd")\nrobot = sim.load_robot("mobile_manipulator.usd")\n\n# Configure sensors\ncamera = sim.add_camera(robot, "camera_link")\nlidar = sim.add_lidar(robot, "lidar_link")\n\n# Set up physics\nsim.set_physics_engine("physx")\nsim.set_gravity([0, 0, -9.81])\n\n# Run simulation\nwhile sim.is_running():\n    # Step physics\n    sim.step()\n    \n    # Get sensor data\n    rgb_image = camera.get_rgb()\n    depth_image = camera.get_depth()\n    point_cloud = lidar.get_points()\n    \n    # Process with AI\n    detections = ai_model.detect_objects(rgb_image)\n    \n    # Control robot\n    robot.set_joint_velocities(compute_control(detections))\n'})}),"\n",(0,r.jsx)(n.h3,{id:"synthetic-data-generation",children:"Synthetic Data Generation"}),"\n",(0,r.jsx)(n.p,{children:"Isaac Replicator enables unlimited training data creation:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import isaacsim.replicator as rep\n\n# Define randomization parameters\ndef randomize_lighting():\n    return rep.distribution.uniform((0.1, 0.1, 0.1), (1.0, 1.0, 1.0))\n\ndef randomize_objects():\n    return {\n        "position": rep.distribution.uniform((-2, -2, 0), (2, 2, 1)),\n        "rotation": rep.distribution.uniform((0, 0, 0), (360, 360, 360)),\n        "scale": rep.distribution.uniform(0.8, 1.2)\n    }\n\n# Create scenario\nwith rep.new_layer():\n    # Random lighting\n    rep.create.light(intensity=randomize_lighting())\n    \n    # Random objects\n    for i in range(10):\n        obj = rep.create.object("cube.usd", **randomize_objects())\n        rep.randomizer.scatter_2d(obj)\n    \n    # Camera setup\n    camera = rep.create.camera(position=(0, 0, 2))\n    \n    # Generate dataset\n    rep.orchestrator.run(\n        num_frames=1000,\n        output_dir="/datasets/synthetic",\n        format="png"\n    )\n'})}),"\n",(0,r.jsx)(n.h3,{id:"domain-randomization",children:"Domain Randomization"}),"\n",(0,r.jsx)(n.p,{children:"Improve model robustness through environmental variation:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Comprehensive randomization\nrandomization_config = {\n    "lighting": {\n        "intensity": rep.distribution.uniform(0.5, 2.0),\n        "color": rep.distribution.uniform((0.5, 0.5, 0.5), (1.5, 1.5, 1.5)),\n        "direction": rep.distribution.uniform(-180, 180)\n    },\n    "materials": {\n        "roughness": rep.distribution.uniform(0.1, 0.9),\n        "metallic": rep.distribution.uniform(0.0, 0.8),\n        "color": rep.distribution.uniform((0.2, 0.2, 0.2), (1.0, 1.0, 1.0))\n    },\n    "objects": {\n        "position_noise": rep.distribution.normal(0, 0.1),\n        "rotation_noise": rep.distribution.normal(0, 15),\n        "scale_variation": rep.distribution.uniform(0.9, 1.1)\n    },\n    "camera": {\n        "intrinsic_noise": rep.distribution.normal(0, 0.01),\n        "extrinsic_noise": rep.distribution.normal(0, 0.05)\n    }\n}\n\n# Apply randomization\nrep.randomizer.apply_randomization(randomization_config)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,r.jsx)(n.h3,{id:"tensorrt-integration",children:"TensorRT Integration"}),"\n",(0,r.jsx)(n.p,{children:"Optimize models for inference performance:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import tensorrt as trt\nfrom isaac import TensorRTModel\n\n# Convert PyTorch model to TensorRT\ndef convert_to_tensorrt(pytorch_model, input_shape):\n    # Create TensorRT builder\n    builder = trt.Builder(trt.Logger(trt.Logger.WARNING))\n    network = builder.create_network()\n    parser = trt.OnnxParser(network, trt.Logger(trt.Logger.WARNING))\n    \n    # Parse ONNX model\n    with open("model.onnx", "rb") as f:\n        parser.parse(f.read())\n    \n    # Build optimized engine\n    config = builder.create_builder_config()\n    config.max_workspace_size = 1 << 30  # 1GB\n    config.set_flag(trt.BuilderFlag.FP16)  # Use FP16 precision\n    \n    engine = builder.build_engine(network, config)\n    \n    # Save engine\n    with open("model.engine", "wb") as f:\n        f.write(engine.serialize())\n    \n    return engine\n\n# Load optimized model in Isaac\nmodel = TensorRTModel("model.engine")\nmodel.optimize_for_device("jetson_orin")\n'})}),"\n",(0,r.jsx)(n.h3,{id:"multi-gpu-and-multi-node-training",children:"Multi-GPU and Multi-Node Training"}),"\n",(0,r.jsx)(n.p,{children:"Scale training across multiple GPUs:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import torch\nfrom torch.nn.parallel import DistributedDataParallel as DDP\n\ndef setup_distributed_training():\n    # Initialize process group\n    torch.distributed.init_process_group(backend='nccl')\n    \n    # Get local rank\n    local_rank = torch.distributed.get_rank()\n    torch.cuda.set_device(local_rank)\n    \n    # Create model\n    model = create_model()\n    model = DDP(model, device_ids=[local_rank])\n    \n    return model\n\n# Training loop with gradient accumulation\ndef train_distributed(model, dataloader, optimizer):\n    model.train()\n    for batch in dataloader:\n        # Forward pass\n        outputs = model(batch['images'])\n        loss = compute_loss(outputs, batch['labels'])\n        \n        # Backward pass with gradient accumulation\n        loss.backward()\n        \n        # Update weights (every N steps)\n        if (step + 1) % accumulation_steps == 0:\n            optimizer.step()\n            optimizer.zero_grad()\n            \n        # Synchronize across GPUs\n        torch.distributed.all_reduce(loss)\n"})}),"\n",(0,r.jsx)(n.h2,{id:"integration-with-ros-2",children:"Integration with ROS 2"}),"\n",(0,r.jsx)(n.h3,{id:"isaac-ros-bridge",children:"Isaac ROS Bridge"}),"\n",(0,r.jsx)(n.p,{children:"Connect Isaac applications with ROS 2:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from isaac_ros_bridge import IsaacROSBridge\nfrom isaac import Application\n\n# Create Isaac application\nisaac_app = Application()\ncamera = isaac_app.add("Camera")\ndetector = isaac_app.add("ObjectDetector")\n\n# Create ROS 2 bridge\nros_bridge = IsaacROSBridge()\n\n# Connect Isaac to ROS 2\nros_bridge.connect_topic(\n    isaac_output=detector.get_output("detections"),\n    ros_topic="/object_detections",\n    ros_type="vision_msgs/Detection2DArray"\n)\n\n# ROS 2 subscriber in Isaac\nros_bridge.create_subscriber(\n    ros_topic="/cmd_vel",\n    isaac_input=controller.get_input("velocity_commands"),\n    ros_type="geometry_msgs/Twist"\n)\n\n# Run integrated system\nisaac_app.run()\n'})}),"\n",(0,r.jsx)(n.h2,{id:"debugging-and-profiling",children:"Debugging and Profiling"}),"\n",(0,r.jsx)(n.h3,{id:"performance-monitoring",children:"Performance Monitoring"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from isaac import Profiler\n\nprofiler = Profiler()\n\n@profiler.profile\ndef perception_pipeline(frame):\n    # Profile each stage\n    with profiler.timer("preprocessing"):\n        processed = preprocess(frame)\n    \n    with profiler.timer("detection"):\n        detections = detect_objects(processed)\n    \n    with profiler.timer("tracking"):\n        tracks = track_objects(detections)\n    \n    return tracks\n\n# Run profiling\nfor frame in test_frames:\n    result = perception_pipeline(frame)\n\n# Print results\nprofiler.print_summary()\n'})}),"\n",(0,r.jsx)(n.h3,{id:"memory-optimization",children:"Memory Optimization"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Monitor GPU memory usage\ndef monitor_gpu_memory():\n    import pynvml\n    pynvml.nvmlInit()\n    \n    handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n    info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n    \n    print(f"GPU Memory: {info.used/1024**2:.1f}MB / {info.total/1024**2:.1f}MB")\n    print(f"Utilization: {info.used/info.total*100:.1f}%")\n\n# Memory-efficient data loading\nfrom torch.utils.data import DataLoader\nfrom isaac.data import EfficientDataset\n\ndataset = EfficientDataset(\n    data_path="/datasets",\n    batch_size=32,\n    num_workers=4,\n    pin_memory=True,\n    persistent_workers=True\n)\n\ndataloader = DataLoader(\n    dataset,\n    batch_sampler=dataset.batch_sampler,\n    num_workers=0,  # Data loading handled by dataset\n    pin_memory=False\n)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"-weekly-project-isaac-perception-pipeline",children:"\ud83c\udfaf Weekly Project: Isaac Perception Pipeline"}),"\n",(0,r.jsx)(n.p,{children:"Build a complete AI perception system using Isaac:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Isaac Sim Environment"}),": Create a photorealistic scene with objects to detect"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Synthetic Dataset"}),": Generate training data using Isaac Replicator"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Model Training"}),": Train an object detection model with domain randomization"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Real-Time Inference"}),": Deploy the model for live detection in simulation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"ROS 2 Integration"}),": Publish detection results to ROS 2 topics"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Performance Optimization"}),": Achieve real-time performance with TensorRT"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"This project demonstrates the complete Isaac workflow from simulation to deployment."}),"\n",(0,r.jsx)(n.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Isaac SDK"})," provides modular components for building complex AI applications"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Isaac Sim"})," enables photorealistic training with unlimited synthetic data"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Domain randomization"})," improves robustness by training on varied conditions"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"TensorRT optimization"})," enables real-time inference on edge devices"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"ROS 2 integration"})," creates unified robotic systems combining AI and control"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Mastering Isaac gives you the power to create intelligent robots that perceive, reason, and act with human-like capabilities. The AI brains you build this week will form the foundation for advanced robotic intelligence in the coming weeks."})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>s});var t=i(6540);const r={},a=t.createContext(r);function o(e){const n=t.useContext(a);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);